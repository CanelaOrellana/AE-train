# Carpeta de C√≥digos

Aqu√≠ se encuentra:
* el c√≥digo [`AutoEncoders.py`](#‚ú®autoencoderspy‚ú®)
* el c√≥digo [`CasoBase_train.ipynb`](#‚ú®casobase_trainipynb‚ú®)
* la carpeta [**Detecci√≥n de Anomal√≠as**](#‚ú®detecci√≥n-de-anomal√≠as‚ú®)

_ _ _
_ _ _
## ‚ú®CasoBase_train.ipynb‚ú®

En este notebook se muestran ejemplos para
- Realizar los entrenamientos utilizando grillas
- Realizar un entrenamiento espec√≠fico
- Cargar los pesos para un uso posterior del modelo

_ _ _
_ _ _
## ‚ú®AutoEncoders.py‚ú®

En este script de python, se encuentran las clases que definen a los objetos [AutoEncoder](#clase-‚ú®autoencoder‚ú®) y [JointAEClassifier](#clase-‚ú®jointaeclassifier‚ú®). A continuaci√≥n les explico qu√© se puede hacer con cada una de ellas, en qu√© consisten los objetos, qu√©e m√©todos traen y cuales son los hiperpar√°metros que pueden utilizar para obtener el autoencoder de sus sue√±os. 

_pd: obvio no olviden que cuando clonen este repo o copien los c√≥digos, podr√°n agregar y quitar los m√©todos que quieran_

### Clase ‚ú®<span style="color:teal">AutoEncoder</span>‚ú®


**Posee los hiperpar√°metros:**
- `h_layer_sizes` <span style="color:green">List [ int ]</span> : recibe una lista, la cual contiene los tama√±os de las capas ocultas del encoder (y por ende, del decoder)  

- `timesteps` <span style="color:green">int</span> : representa la cantidad de pasos en el tiempo que se reciben, es el tama√±o de la ventana temporal. (Si se trabajara con frases, ser√≠a el n√∫mero de palabras)  

- `learning_rate` <span style="color:green">float</span> :  corresponde al learning rate de toda la vida  

- `dropout` <span style="color:green">float</span> : corresponde al dropout que se aplica luego de la capa de salida del encoder y del decoder.  
_pd: nunca obtuve mejor rendimiento utiliz√°ndolo_  

- `n_features_in` <span style="color:green">int</span> : es el n√∫mero de caracter√≠sticas de entrada de los datos que se est√°n ingresando, en mi caso, correspond√≠a a la cantidad de sensores que estaba considerando en mis datos de entrenamiento  

- `batch_size` <span style="color:green">int</span> : es el batch_size de toda la vida.  
_pd: en mi experiencia es mejor utilizar n√∫meros peque√±os (menores a 10), no s√≥lo por el desempe√±o obtenido, sino que tambi√©n por la capacidad de la gpu que utilic√©_  

- `optim` <span style="color:green">string</span>:  puede ser <span style="color:orange">'Adam'</span>, <span style="color:orange">'RAdam'</span> o <span style="color:orange">'AdamW'</span> y permite elegir qu√© optimizador desea usar en el entrenamiento futuro.  
_pd: s√≥lo se configur√≥ para esas 3 posibilidades, si se desea utilizar otro optimizador, se debe modificar un poco el c√≥digo.  
pd 2: siempre me funcion√≥ mejor RAdam (tiene sentido)_  

- `epochs` <span style="color:green">int</span> : representa el n√∫mero de √©pocas (m√°ximo) durante las que se llevar√° a cabo el entrenamiento.  

- `verbose` <span style="color:green">int</span> : permite controlar cu√°ntos mensajes informativos se quiere recibir durante el entrenamiento. Como regla general, se reciben mensajes en las √©pocas m√∫ltiplos del n√∫mero que se utilice, el mensaje incluye: √©poca, loss en validaci√≥n, R^2 en validaci√≥n y R^2 en entrenamiento.  
Tambi√©n hay algunos n√∫meros especiales:
    - **0**: Se imprime el n√∫mero de capas, leearning rate, dropout y paciencia que se est√°n utilizando en el entrenamiento (No se imprime nada durante los bucles de entrenamiento).  
    _pd: el objetivo de esto era seguirle la pista a los entrenamientos al utilizar GridSearch_  
    - **5**: Adem√°s de los mensajes cada 5 √©pocas, al finalizar el entrenamiento se muestran los gr√°ficos de **loss vs √©pocas** y de **r^2 vs √©pocas**. 

- `patience` <span style="color:green">int</span> : representa la cantidad de √©pocas que se tendr√° paciencia si el modelo no est√° bajando su funci√≥n de _loss_, en caso de que se superen las √©pocas de paciencia, se detendr√° tempranamente el entrenamiento del modelo, ya que no se est√°n obteniendo mejoras y no queremos malgastar ni tiempo ni recursos de computo.

**M√©todos que posee:**

- `build_model`: permite construir la arquitectura del modelo seg√∫n los hiperpar√°metros antes definidos. Posee 3 clases locales
    - **Encoder:** permite crear un objeto Encoder a partir de los hiperpar√°metros antes definidos, incluyendo su m√©todo fordward.    
    - **Decoder:** permite crear un objeto Decoder a partir de los hiperpar√°metros antes definidos, incluyendo su m√©todo fordward.  
    - **Autoencoder:** permite crear al objeto Autoencoder, que consiste en un Encoder seguido de un Decoder, incluyendo su m√©todo fordward.  
En este m√©todo retorna el modelo de arquitectura autoencoder, tambi√©n se definen aqu√≠, la funci√≥n de loss y el optimizador del modelo.  

-  `fit`: este m√©todo permite llevar a cabo los bucles de entrenamiento del modelo, utilizando de apoyo a las funciones `ftrain` y `fevaluate`. Para funcionar recibe:
    - **X**: conjunto de datos de entrenamiento, deben estar en el formato esperado `[# muestras temporales por ventana, # caracter√≠sticas consideradas]`
    - `p_train` <span style="color:green">float</span> : representa el porcentaje de X que se usar√° para entrenamiento, el porcentaje restante se utilizar√° para validaci√≥n.  
    _pd: estos AEs est√°n dise√±ados para el procesamiento de se√±ales, por lo que no se realiza shuffle de los conjuntos. Tenerlo presente si se desea utilizar estos c√≥digos con otro tipo de datos_  

- `predict`: este m√©todo permite predecir utilizando el modelo, es decir entrega la se√±al reconstruida.

- `score`: este m√©todo permite calcular una m√©trica para evaluar la predicci√≥n del modelo. En el c√≥digo se puede modificar para utilizar mse o r^2.  
_pd: este m√©todo es utilizado por GridSearch para definir qu√© modelos de los entrenados son mejores_

- `save_weights`: este m√©todo permite guardar los pesos del modelo entrenado, para en un futuro poder simplemente cargarlos en el modelo, sin necesidad de reentrenar.  

- `transform`: este m√©todo permite transformar los datos a la forma del espacio latente del autoencoder.  
_pd: existe por completitud de los m√©todos que se implementan en los modelos de scikit learn, que es para los que funciona GridSearch de manera nativa_  
_pd 2: pero por su puesto, el espacio latente que se produce es de gran inter√©s üíó_

- `inverse_transform`: este m√©todo permite transformar los datos desde el espacio latente al espacio de entrada al autoencoder.  
_pd: tambi√©n existe por completitud de los m√©todos que se implementan en los modelos de scikit learn, que es para los que funciona GridSearch de manera nativa_

#### Clase ‚ú®AutoEncoderWrapper‚ú®
Esta clase sirve para _envolver_ nuestro autoencoder creado con la clase explicada anteriormente. Por lo que recibe exactamente los mismos hiperpar√°metros que <span style="color:teal">AutoEncoder</span>. Sus m√©todos se describen a continuaci√≥n

- `_create_autoencoder`: este m√©todo retorna un objeto de la clase AutoEncoder, con los hiperpar√°metros recibidos.
- `fit`: este m√©todo utiliza el m√©todo anterior para crear un autoencoder y lo entrena llamando al m√©todo `fit` de AutoEncoder.
- `predict`: este m√©todo llama al m√©todo `predict` de AutoEncoder.
- `score`: este m√©todo llama al m√©todo `score` de AutoEncoder.
- `save_weights`: este m√©todo llama al m√©todo `save_weights` de AutoEncoder.

Este objeto permite utilizar los m√©todos de `GridSearch` o `HalvingGridSearch` para encontrar los mejores hiperpar√°metros


### Clase ‚ú®<span style="color:teal">JointAEClassifier</span>‚ú®


**Posee los hiperpar√°metros:**

- `h_layer_sizes` <span style="color:green">List [ int ]</span> : recibe una lista, la cual contiene los tama√±os de las capas ocultas del encoder (y por ende, del decoder)  

- `timesteps` <span style="color:green">int</span> : representa la cantidad de pasos en el tiempo que se reciben, es el tama√±o de la ventana temporal. (Si se trabajara con frases, ser√≠a el n√∫mero de palabras)  

- `learning_rate` <span style="color:green">float</span> : corresponde al learning rate que se aplica en el autoencoder.

- `learning_rate_c` <span style="color:green">float</span> : corresponde al learning rate que se aplica en el clasificador.

- `dropout_ae` <span style="color:green">float</span> : corresponde al dropout que se aplica luego de la capa de salida del encoder y del decoder.  
_pd: nunca obtuve mejor rendimiento utiliz√°ndolo_  

- `dropout_c` <span style="color:green">float</span> : corresponde al dropout que se aplica en la √∫ltima capa oculta del clasificador.  
_pd: en algunos casos si se observ√≥ mejor rendimiento utiliz√°ndolo_  

- `n_features_in` <span style="color:green">int</span> : es el n√∫mero de caracter√≠sticas de entrada de los datos que se est√°n ingresando, en mi caso, correspond√≠a a la cantidad de sensores que estaba considerando en mis datos de entrenamiento.

- `batch_size` <span style="color:green">int</span> : es el batch_size de toda la vida.  
_pd: en mi experiencia es mejor utilizar n√∫meros peque√±os (iguales o menores a 5), no s√≥lo por el desempe√±o obtenido, sino que tambi√©n por la capacidad de la gpu que utilic√©_  

- `alpha` <span style="color:green">float</span> : su objetivo es determinar la participaci√≥n del desempe√±o del autoencoder en la funci√≥n de _loss_. Es decir, el valor de la _loss_ se pondera por $\alpha$, por lo que, si su valor es 1 s√≥lo se considera la funci√≥n de _loss_ autoencoder y si es 0 s√≥lo se considera la funci√≥n de _loss_ del clasificador. Por otra parte, lo que se considera de la funci√≥n de _loss_ del clasificador es $1 - \alpha$.  

- `optim` <span style="color:green">string</span>:  puede ser <span style="color:orange">'Adam'</span>, <span style="color:orange">'RAdam'</span> o <span style="color:orange">'AdamW'</span> y permite elegir qu√© optimizador desea usar en el entrenamiento futuro.  
_pd: s√≥lo se configur√≥ para esas 3 posibilidades, si se desea utilizar otro optimizador, se debe modificar un poco el c√≥digo.  
pd 2: siempre me funcion√≥ mejor RAdam (tiene sentido)_  

- `stat` <span style="color:green">string</span> : permite elegir el estad√≠stico entre los timesteps del espacio latente que se usar√° como entrada al clasificados, si es que se usar√° alguno. Las opciones que permite son:
    - <span style="color:orange">'mean'</span> : *promedio* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'std'</span> : *desviaci√≥n est√°ndar* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'median'</span> : *mediana* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'var'</span> : *varianza* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'min'</span> : *m√≠nimo* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'max'</span> : *m√°ximo* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">'mode'</span> : *moda* para cada dimensi√≥n entre los timesteps
    - <span style="color:orange">''</span> : se toma √∫nicamente el *√∫ltimo* timestep de la ventana

- `epochs` <span style="color:green">int</span> : representa el n√∫mero de √©pocas (m√°ximo) durante las que se llevar√° a cabo el entrenamiento.  

- `verbose` <span style="color:green">int</span> : permite controlar cu√°ntos mensajes informativos se quiere recibir durante el entrenamiento. Como regla general, se reciben mensajes en las √©pocas m√∫ltiplos del n√∫mero que se utilice, el mensaje incluye: √©poca, loss en validaci√≥n, R^2 en validaci√≥n y R^2 en entrenamiento.  
Tambi√©n hay algunos n√∫meros especiales:
    - **0**: Se imprime el n√∫mero de capas, leearning rate, dropout y paciencia que se est√°n utilizando en el entrenamiento (No se imprime nada durante los bucles de entrenamiento).  
    _pd: el objetivo de esto era seguirle la pista a los entrenamientos al utilizar GridSearch_  
    - **5**: Adem√°s de los mensajes cada 5 √©pocas, al finalizar el entrenamiento se muestran los gr√°ficos de **loss vs √©pocas** y de **r^2 vs √©pocas**. 

- `patience` <span style="color:green">int</span> : representa la cantidad de √©pocas que se tendr√° paciencia si el modelo no est√° bajando su funci√≥n de _loss_, en caso de que se superen las √©pocas de paciencia, se detendr√° tempranamente el entrenamiento del modelo, ya que no se est√°n obteniendo mejoras y no queremos malgastar ni tiempo ni recursos de computo.

- `n_classes` <span style="color:green">int</span> : representa la cantidad de clases posibles para el clasificador, depende de qu√© se quiera clasificar con √©l.

**M√©todos que posee:**

- `build_model`: permite construir la arquitectura del modelo seg√∫n los hiperpar√°metros antes definidos. Posee 4 clases locales
    - **Encoder:** permite crear un objeto Encoder a partir de los hiperpar√°metros antes definidos, incluyendo su m√©todo fordward.    
    - **Decoder:** permite crear un objeto Decoder a partir de los hiperpar√°metros antes definidos, incluyendo su m√©todo fordward.  
    - **Classifier:** permite crear un objeto Classifier a partir de los hiperpar√°metros antes definidos, considera 2 capas ocultas y la capa de salida. Incluye su m√©todo fordward.  
    - **AEClassifier:** permite crear objeto AEClassifier, que consiste en un AutoEncoder a cuyo espacio latente se encuentra conectado un clasificador. Incluye su m√©todo fordward.  
En este m√©todo retorna el modelo de arquitectura conjunta entre autoencoder y clasificador, tambi√©n se definen aqu√≠, las funciones de _loss_, el optimizador del modelo y el scheduler para modificar el learning rate.  

- `fdataloader`: este m√©todo lleva a cabo las funciones del dataloader del modelo, por lo que retorna los dataloader para entrenamiento y validaci√≥n. Para funcionar recibe: 
    - **X**: conjunto de datos de entrenamiento, deben estar en el formato esperado `[# muestras temporales por ventana, # caracter√≠sticas consideradas]`
    - **y**: conjunto de etiquetas correspondientes a los datos de entrenamiento `[# muestras temporales por ventana]`
    - `p_train` <span style="color:green">float</span> : representa el porcentaje de X que se usar√° para entrenamiento, el porcentaje restante se utilizar√° para validaci√≥n.  
    _pd: estos AEs est√°n dise√±ados para el procesamiento de se√±ales, por lo que no se realiza shuffle de los conjuntos. Tenerlo presente si se desea utilizar estos c√≥digos con otro tipo de datos_

-  `fit`: este m√©todo permite llevar a cabo los bucles de entrenamiento del modelo, utilizando de apoyo a las funciones `f_train` y `f_evaluate`. Recibe **X**, **y**, `p_train` para crear los dataloaders mediante `fdataloader`.

- `predict`: este m√©todo permite predecir utilizando el modelo. Entrega dos salidas: la se√±al reconstru√≠da y el resultado del clasificador.

- `score`: este m√©todo permite calcular una m√©trica para evaluar la predicci√≥n del modelo. Utiliza el promedio entre el r^2 de la reconstrucci√≥n y el accuracy de la clasificaci√≥n.
_pd: este m√©todo es utilizado por GridSearch/HalvingGridSearch para definir qu√© modelos de los entrenados son mejores_

- `save_weights`: este m√©todo permite guardar los pesos del modelo entrenado, para en un futuro poder simplemente cargarlos en el modelo, sin necesidad de reentrenar.  

- `transform`: este m√©todo permite transformar los datos a la forma del espacio latente del autoencoder.  
_pd: existe por completitud de los m√©todos que se implementan en los modelos de scikit learn, que es para los que funciona GridSearch de manera nativa_  
_pd 2: pero por su puesto, el espacio latente que se produce es de gran inter√©s üíó_

- `inverse_transform`: este m√©todo permite transformar los datos desde el espacio latente al espacio de entrada al autoencoder.  
_pd: tambi√©n existe por completitud de los m√©todos que se implementan en los modelos de scikit learn, que es para los que funciona GridSearch de manera nativa_

#### Clase ‚ú®JointAEClassifierWrapper‚ú®
Esta clase sirve para _envolver_ nuestro autoencoder creado con la clase explicada anteriormente. Por lo que recibe exactamente los mismos hiperpar√°metros que <span style="color:teal">JointAEClassifier</span>. Sus m√©todos se describen a continuaci√≥n

- `_create_aeclassifier`: este m√©todo retorna un objeto de la clase JointAEClassifier, con los hiperpar√°metros recibidos.
- `fit`: este m√©todo utiliza el m√©todo anterior para crear un autoencoder y lo entrena llamando al m√©todo `fit` de JointAEClassifier.
- `predict`: este m√©todo llama al m√©todo `predict` de JointAEClassifier.
- `score`: este m√©todo llama al m√©todo `score` de JointAEClassifier.
- `save_weights`: este m√©todo llama al m√©todo `save_weights` de JointAEClassifier.

Este objeto permite utilizar los m√©todos de `GridSearch` o `HalvingGridSearch` para encontrar los mejores hiperpar√°metros



_ _ _
_ _ _
## ‚ú®Detecci√≥n de Anomal√≠as‚ú®

En esta carpeta a√∫n no pueden encontrar nada, pero pr√≥ximamente estar√°n los c√≥digos de c√≥mo se puede realizar detecci√≥n de anomal√≠as a partir de los autoencoders creados 